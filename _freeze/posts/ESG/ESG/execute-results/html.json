{
  "hash": "c91f1d6770f4e3048dbd681f51cfa2ae",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Automated evaluation of companies in ESG-screened ETF\"\nauthor: \"Niek Van Wettere\"\ndate: \"2025-12-28\"\ncategories: [AI]\nimage: etf_ai_image.jpg\nformat: \n  html:\n    self-contained: true\n    toc: true\n    number-sections: true\n    code-fold: false\n    code-overflow: wrap\n    df-print: paged\neditor: source\n---\n\nThis blog post is about automated evaluation of companies listed in an ESG-screened ETF. We focus on the ETF 'Xtrackers MSCI World ESG UCITS'. For each company in the ETF, we try to gather news and classify the news according to its negative ESG-value.\n\nMost of the analysis is done in Python, because Python offers more readily available tools for this type of analysis.\n<br />\n\n# Virtual environment\n\n## Create virtual environment\n\nFirst, we have to set up a virtual environment with the necessary packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::virtualenv_create(\n  envname = \"esg-py\",\n  packages = c(\"pandas\", \"requests\", \"lxml\")\n)\n```\n:::\n\n\n<br />\n\nAdditionally, we create a requirements.txt file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# requirements.txt\npython <- reticulate::py_config()$python\nsystem(sprintf('\"%s\" -m pip freeze > requirements.txt', python))\n```\n:::\n\n\n<br />\n\nExtra packages can be installed into the virtual environment via the command below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install extra packages\nreticulate::py_install(\"nltk\", envname = \"esg-py\")\n```\n:::\n\n\n<br />\n\n## Activate virtual environment\n\nOnce the virtual environment is created, we have to activate it so that the installed packages are available for further analysis of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nreticulate::use_virtualenv(\"esg-py\", required = TRUE)\n```\n:::\n\n\n<br />\n\n# Retrieve list of holdings\n\nWe scrape the companies that make up the ETF from the web.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport requests\nimport pandas as pd\nfrom io import StringIO  \n\nurl = \"https://companiesmarketcap.com/xtrackers-msci-world-esg-ucits-etf-1c/holdings/\"\n\n# Fetch the HTML\nresponse = requests.get(url)\nresponse.raise_for_status()\nhtml_text = response.text\n\n# Wrap HTML in StringIO\ntables = pd.read_html(StringIO(html_text))\n\n# Extract the first table\ndf_holdings = tables[0]\n\n# Optional: clean column names\ndf_holdings.columns = [\"Weight\", \"Name\", \"ISIN\", \"Country\"]\n\n# Save to CSV\ndf_holdings.to_csv(\"xzw0_full_holdings.csv\", index=False)\n```\n:::\n\n\n<br />\n\nNow that the list of holdings is available in a csv-file, we can load it from there for further analysis.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport pandas as pd\ndata_holdings = pd.read_table('xzw0_full_holdings.csv', delimiter=',')\n```\n:::\n\n\n\n<br />\n\n# Retrieve news\n\nWe start with defining two functions that 'clean' the company names and build a keyword for search. A possible improvement is to use all known name variants of the same ISIN-number.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport re\n\ndef clean_company_name(name):\n    # Uppercase for consistency\n    name = name.upper()\n\n    # Remove common legal suffixes\n    suffixes = [\n        r'\\bINC\\b', r'\\bCORP\\b', r'\\bCORPORATION\\b',\n        r'\\bGROUP\\b', r'\\bGROEP\\b',\n        r'\\bNV\\b', r'\\bAG\\b',\n        r'\\bLTD\\b', r'\\bLIMITED\\b', r'\\bCO\\b',\n        r'\\bCLASS A\\b', r'\\bCLASS B\\b', r'\\bPLC\\b'\n    ]\n\n    for s in suffixes:\n        name = re.sub(s, '', name)\n\n    \n    # Replace & with space\n    name = name.replace('&', ' ')\n\n    # Remove extra whitespace\n    name = re.sub(r'\\s+', ' ', name).strip()\n\n    return name\n```\n:::\n\n\n<br />\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nfrom nltk.corpus import wordnet as wn\nfrom wordfreq import zipf_frequency\n\ndef is_common_english_word(word, threshold=3.5):\n    \"\"\"\n    Zipf frequency:\n    ~1–2  rare\n    ~3    uncommon\n    ~4–5  common\n    ~6–7  very common\n    \"\"\"\n    \n    is_lexical_word = bool(wn.synsets(word.lower()))  # Proper nouns should be excluded this way. This would also exclude multiword expressions.\n    is_common_usage = zipf_frequency(word.lower(), \"en\") >= threshold\n\n    is_common_word = is_lexical_word and is_common_usage\n    \n    return is_common_word\n```\n:::\n\n\n<br />\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ndef build_keyword(name):\n    cleaned = clean_company_name(name)\n\n    # If very short or common English word, expand the query with \"company\"\n    if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):\n        return f'\"{cleaned}\" AND \"company\"'\n\n    # Quote multi-word company names\n    if ' ' in cleaned:\n        return f'\"{cleaned}\"'\n\n    return cleaned\n```\n:::\n\n\n<br />\n\nCommon English words are accompanied by 'company' in the search term, cf. example below.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nbuild_keyword(\"MICROSOFT CORP\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'MICROSOFT'\n```\n\n\n:::\n\n```{.python .cell-code}\nbuild_keyword(\"EMPIRE CORP\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'\"EMPIRE\" AND \"company\"'\n```\n\n\n:::\n:::\n\n\n<br />\n\nConsequently, we use the API of the GDELT-project to retrieve news titles concerning the companies. We limit the search to certain ESG-themes. These data are very limited (only titles) and it's not possible to reliably link them to a specific company. Therefore, we have to be cautious interpreting the data. Moreover, the number of hits is also restricted per call. A more comprehensive approach would be to download the complete GDELT-files, but this is beyond the scope of the current demonstration. A major advantage is that the data are openly available, without cost.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom gdeltdoc import GdeltDoc, Filters\nimport pandas as pd\nimport time\n\ngd = GdeltDoc()\nresults = []\n\nESG_THEMES = [  # http://data.gdeltproject.org/api/v2/guides/LOOKUP-GKGTHEMES.TXT\n    \"WB_1786_ENVIRONMENTAL_SUSTAINABILITY\",\n    \"WB_2089_ETHICS_AND_CODES_OF_CONDUCT\",\n    \"WB_417_CORPORATE_GOVERNANCE\",\n    \"WB_2507_HUMAN_RIGHTS_ABUSES_AND_VIOLATIONS\"\n]\n\nTRUSTED_DOMAINS = [\n    \"reuters.com\",\n    \"bloomberg.com\",\n    \"ft.com\",\n    \"wsj.com\",\n    \"nytimes.com\",\n    \"theguardian.com\",\n    \"economist.com\"\n]\n\nfor _, row in data_holdings.iterrows():\n    keyword = build_keyword(row[\"Name\"])\n\n    for theme in ESG_THEMES:\n        try:\n            f = Filters(\n                keyword=keyword,\n                language=\"English\",\n                theme=theme,  \n               #domain=TRUSTED_DOMAINS,\n                start_date=\"2023-01-01\",\n                end_date=\"2025-12-26\"\n            )\n\n            articles = gd.article_search(f)\n\n            if articles is None or len(articles) == 0:\n                continue\n\n            gkg = pd.DataFrame(articles)\n\n            # Add metadata\n            gkg[\"ISIN\"] = row[\"ISIN\"]\n            gkg[\"Name\"] = row[\"Name\"]\n            gkg[\"Theme\"] = theme  \n\n            results.append(gkg)\n\n            time.sleep(0.5)  # avoid throttling\n\n        except Exception as e:\n            print(f\"Error for {row['Name']} | Theme {theme}: {e}\")\n\n# Combine all results\nnews_df_original = pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n```\n:::\n\n\nThe results are saved to a csv-file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Save to CSV\nnews_df_original.to_csv(\"news_df_original.csv\", index=False)\n```\n:::\n\n\n<br />\n\nWe clean the results further, removing for example news title duplicates.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Delete rows with no title.\nnews_df = news_df_original.dropna(subset=[\"title\"])\nnews_df = news_df[news_df[\"title\"].str.strip() != \"\"]\n\n\n# The (first part of the) company name must be in the title of the article.\nimport re\n\ndef name_in_title(row):\n    if pd.isna(row[\"title\"]) or pd.isna(row[\"Name\"]):\n        return False\n    # Use first token to avoid regex length issues\n    token = row[\"Name\"].split()[0]\n    return re.search(rf\"\\b{re.escape(token)}\\b\", row[\"title\"], re.IGNORECASE) is not None\n\nnews_df = news_df[news_df.apply(name_in_title, axis=1)]\n\n\n# Maximally remove identical titles.\nnews_df = news_df.drop_duplicates(subset=\"title\", keep=\"first\")\n```\n:::\n\n\n<br />\n\nThe results are saved to a csv-file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Save to CSV\nnews_df.to_csv(\"news_df.csv\", index=False)\n```\n:::\n\n\n<br />\n\nIf we continue the analysis at a later moment, we can now load the data from the csv-file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport pandas as pd\nnews_df = pd.read_table('news_df.csv', delimiter=',')\n```\n:::\n\n\n<br />\n\n# AI-analysis\n\nBy means of a Transformer-model, we aim to classify the news titles on their ESG-value.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nfrom transformers import pipeline\nimport pandas as pd\n\nnli = pipeline(\n    \"zero-shot-classification\",\n    model=\"facebook/bart-large-mnli\",\n    device=-1  # CPU\n)\n\n```\n:::\n\n\n<br />\n\nWe use two functions, one to capture the sentiment about the company and one to ascertain whether the news title has negative or positive ESG-value.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ndef targeted_company_sentiment(title: str, company: str):\n    \"\"\"\n    Returns: sentiment_label, confidence_score\n    \"\"\"\n\n    candidate_labels = [\"negative\", \"positive\", \"neutral\"]\n\n    hypothesis_template = \"The article is about the company \" + company + \" and expresses {} sentiment toward it.\"\n\n    result = nli(\n        title,\n        candidate_labels,\n        hypothesis_template=hypothesis_template,\n        truncation=True\n    )\n\n    sentiment = result[\"labels\"][0]\n    confidence = result[\"scores\"][0]\n\n    return sentiment, confidence\n\n```\n:::\n\n\n\n<br />\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nESG_LABELS = [\n    \"negative ESG impact\",\n    \"positive ESG impact\",\n    \"not ESG related\"\n]\n\ndef esg_relevance_and_polarity(title: str):\n    \"\"\"\n    Returns: esg_label, confidence_score\n    \"\"\"\n    result = nli(\n        title,\n        ESG_LABELS,\n        truncation=True\n    )\n\n    return result[\"labels\"][0], result[\"scores\"][0]\n\n```\n:::\n\n\n<br />\n\nBoth inputs are used to establish a final evaluation.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ndef classify_esg_title(\n    title: str,\n    company: str,\n    sentiment_threshold=0.8,\n    esg_threshold=0.8\n):\n    \"\"\"\n    Convergent ESG classifier\n    Returns: label, confidence\n    \"\"\"\n\n    sentiment, sent_conf = targeted_company_sentiment(title, company)\n    esg_label, esg_conf = esg_relevance_and_polarity(title)\n\n    # Normalize ESG polarity\n    esg_polarity = {\n        \"negative ESG impact\": \"negative\",\n        \"positive ESG impact\": \"positive\",\n        \"not ESG related\": \"neutral\"\n    }[esg_label]\n\n    # Weak confidence for at least one of the two thresholds → neutral\n    if sent_conf < sentiment_threshold or esg_conf < esg_threshold:\n        return \"neutral\", None\n\n    # Both strong\n    if sentiment == esg_polarity:\n        return f\"{sentiment} ESG\", (sent_conf + esg_conf) / 2\n\n    # Remaining is neutral.\n    return \"neutral\", None\n\n```\n:::\n\n\n<br />\n\nThe labeling is performed for each row of the dataset.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\ndef classify_dataframe(df: pd.DataFrame):\n    \n    df = df.copy()\n    \n    labels = []\n    confidences = []\n\n    for _, row in df.iterrows():\n        label, conf = classify_esg_title(\n            title=row[\"title\"],\n            company=row[\"Name\"]\n        )\n        labels.append(label)\n        confidences.append(conf)\n\n    df[\"ESG_Label\"] = labels\n    df[\"ESG_Confidence\"] = confidences\n\n    return df\n\n```\n:::\n\n\n<br />\n\nAll the necessary functions are defined, now we can apply them to the dataframe with news titles.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nnews_df = classify_dataframe(news_df)\n```\n:::\n\n\n<br />\n\nThe results are saved to a csv-file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Save to CSV\nnews_df.to_csv(\"news_df_with_esg.csv\", index=False)\n```\n:::\n\n\n<br />\n\nIf we continue the analysis at a later moment, we can now load the data from the csv-file.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport pandas as pd\nnews_df = pd.read_table('news_df_with_esg.csv', delimiter=',')\n```\n:::\n\n\n<br />\n\n\nFinally, we cite the titles that were identified as 'negative ESG', at least according to our model. Several results appear to be unreliable. For example, company names that are too close to 'regular' words (such as 'Pandora box') cause issues.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nimport pandas as pd\n\n# Filter only negative ESG labels\nneg_df = news_df[news_df[\"ESG_Label\"] == \"negative ESG\"]\nneg_df_table = neg_df[[\"title\", \"Name\"]]\n```\n:::\n\n\n<br />\n\n\n```{.python .cell-code}\npd.set_option(\"display.max_colwidth\", None)\n\nhtml_table = neg_df_table.to_html(\n    index=False,\n    classes=\"table table-striped\"\n)\n\nscrollable_html = f\"\"\"\n<div style=\"max-height: 400px; overflow-y: auto; border: 1px solid #ddd;\">\n    {html_table}\n</div>\n\"\"\"\n\nscrollable_html\n```\n\n'\\n<div style=\"max-height: 400px; overflow-y: auto; border: 1px solid #ddd;\">\\n    <table border=\"1\" class=\"dataframe table table-striped\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th>title</th>\\n      <th>Name</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>NVIDIA expands presence in occupied Palestine despite AI role in Israeli genocide in Gaza</td>\\n      <td>NVIDIA CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Violating the Terms of Service : Microsoft , Azure and the IDF</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Why top Microsoft investor voted against CEO Satya Nadella</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Protest planned at Microsoft HQ as activists urge company to cut ties with Israeli military</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Activists urged Microsoft to cut ties with Israeli military during protest at HQ</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>EFF and Five Human Rights Organizations Urge Action Around Microsoft Role in Israel War on Gaza</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>ICCL files complaint against Microsoft over Israeli data</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Ireland called to investigate Microsoft over Israeli military data</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Microsoft engineer quits because Israeli military is client : report</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Irish Council for Civil Liberties files Microsoft Gaza complaint to DPC</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Microsoft Ends Azure Services Tied to IDF Unit Accused of Monitoring Palestinians</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Rights groups , activists urge Microsoft to cut all military ties with Israel after partial service suspension</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Microsoft pulls the plug on Israel and shoots itself in the foot</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Hi - tech holocaust : How Microsoft aids the Gaza genocide</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Israel / Palestine : Microsoft Should Avoid Contributing to Rights Abuses</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Hi - Tech Holocaust : How Microsoft Aids The Gaza Genocide</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Microsoft forced to block Israel use of its cloud , AI in mass spying of Palestinians</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Legal groups warn Microsoft could face criminal liability for role in Israel Gaza genocide</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>ICC Ditches Microsoft for Open Desk Amid U . S . Retaliation Risks</td>\\n      <td>MICROSOFT CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Lip - Bu Tan venture ties complicate Intel strategic dealmaking</td>\\n      <td>INTEL CORPORATION CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Intel CEO dual roles questioned amid conflicts claims</td>\\n      <td>INTEL CORPORATION CORP</td>\\n    </tr>\\n    <tr>\\n      <td>The Vulcan - ReElement Deal Everyone Buying And the October 2026 Deadline That Could Sink It - MP Materials ( NYSE : MP ), Intel ( NASDAQ : INTC )</td>\\n      <td>INTEL CORPORATION CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Top Intel Committee lawmaker warns strike video confirms US committed a war crime</td>\\n      <td>INTEL CORPORATION CORP</td>\\n    </tr>\\n    <tr>\\n      <td>Troubled by US Venezuela operation , Europeans limit intel sharing</td>\\n      <td>INTEL CORPORATION CORP</td>\\n    </tr>\\n    <tr>\\n      <td>A disabled mom survived the Eaton fire . The recovery is killing her</td>\\n      <td>EATON PLC</td>\\n    </tr>\\n    <tr>\\n      <td>Synopsys , Inc . Sued for Securities Law Violations - Contact the DJS Law Group to Discuss Your Rights</td>\\n      <td>SYNOPSYS INC</td>\\n    </tr>\\n    <tr>\\n      <td>General strike in Greece over 13 - hour workday plans</td>\\n      <td>WORKDAY INC CLASS A</td>\\n    </tr>\\n    <tr>\\n      <td>Trump Crypto Ties Come Under Fire From House Democrats :  The Most Corrupt Crypto Startup Operation  - Trump Media &amp; Tech Gr ( NASDAQ : DJT )</td>\\n      <td>NASDAQ INC</td>\\n    </tr>\\n    <tr>\\n      <td>Kerry woman recalls domestic abuse horror -  I wake at night thinking I hear his voice in the room</td>\\n      <td>KERRY GROUP PLC</td>\\n    </tr>\\n    <tr>\\n      <td>Pandora Box : The Real Dangers Of The Gene Technology Bill</td>\\n      <td>PANDORA</td>\\n    </tr>\\n    <tr>\\n      <td>Dick Cheney helped design the  war on terror . It opened a Pandora box that still hasnt been closed</td>\\n      <td>PANDORA</td>\\n    </tr>\\n    <tr>\\n      <td>Analysis : Dick Cheney helped design the  war on terror . It opened a Pandora box that still hasnt been closed</td>\\n      <td>PANDORA</td>\\n    </tr>\\n    <tr>\\n      <td>Telenor may be sued over sharing of customer data with Myanmar junta</td>\\n      <td>TELENOR</td>\\n    </tr>\\n    <tr>\\n      <td>SHOCKING ! Report exposes bad things happening at Kingfisher oil project</td>\\n      <td>KINGFISHER PLC</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>\\n'\n\n\n<br />\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}