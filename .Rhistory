import pandas as pd
data_holdings = pd.read_table('xzw0_full_holdings.csv', delimiter=',')
import re
def clean_company_name(name):
# Uppercase for consistency
name = name.upper()
# Remove common legal suffixes
suffixes = [
r'\bINC\b', r'\bCORP\b', r'\bCORPORATION\b',
r'\bGROUP\b', r'\bGROEP\b',
r'\bNV\b', r'\bAG\b',
r'\bLTD\b', r'\bLIMITED\b', r'\bCO\b',
r'\bCLASS A\b', r'\bCLASS B\b', r'\bPLC\b'
]
for s in suffixes:
name = re.sub(s, '', name)
# Replace & with space
name = name.replace('&', ' ')
# Remove extra whitespace
name = re.sub(r'\s+', ' ', name).strip()
return name
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short, expand it with company
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND company'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
build_keyword("Empire NV")
build_keyword("Empire NV")
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short, expand it with company
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND ("company" OR "firm")'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
build_keyword("Empire NV")
import re
def clean_company_name(name):
# Uppercase for consistency
name = name.upper()
# Remove common legal suffixes
suffixes = [
r'\bINC\b', r'\bCORP\b', r'\bCORPORATION\b',
r'\bGROUP\b', r'\bGROEP\b',
r'\bNV\b', r'\bAG\b',
r'\bLTD\b', r'\bLIMITED\b', r'\bCO\b',
r'\bCLASS A\b', r'\bCLASS B\b', r'\bPLC\b'
]
for s in suffixes:
name = re.sub(s, '', name)
# Replace & with space
name = name.replace('&', ' ')
# Remove extra whitespace
name = re.sub(r'\s+', ' ', name).strip()
return name
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND ("company" OR "firm")'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
from gdeltdoc import GdeltDoc, Filters
import pandas as pd
import time
gd = GdeltDoc()
results = []
ESG_THEMES = [  # http://data.gdeltproject.org/api/v2/guides/LOOKUP-GKGTHEMES.TXT
"WB_1786_ENVIRONMENTAL_SUSTAINABILITY",
"WB_2089_ETHICS_AND_CODES_OF_CONDUCT",
"WB_417_CORPORATE_GOVERNANCE",
"WB_2507_HUMAN_RIGHTS_ABUSES_AND_VIOLATIONS"
]
TRUSTED_DOMAINS = [
"reuters.com",
"bloomberg.com",
"ft.com",
"wsj.com",
"nytimes.com",
"theguardian.com",
"economist.com"
]
for _, row in data_holdings.iterrows():
keyword = build_keyword(row["Name"])
for theme in ESG_THEMES:
try:
f = Filters(
keyword=keyword,
language="English",
theme=theme,
#domain=TRUSTED_DOMAINS,
start_date="2023-01-01",
end_date="2025-12-26"
)
articles = gd.article_search(f)
if articles is None or len(articles) == 0:
continue
gkg = pd.DataFrame(articles)
# Add metadata
gkg["ISIN"] = row["ISIN"]
gkg["Name"] = row["Name"]
gkg["Theme"] = theme
results.append(gkg)
time.sleep(0.5)  # avoid throttling
except Exception as e:
print(f"Error for {row['Name']} | Theme {theme}: {e}")
# Combine all results
news_df_original = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
View(news_df_original)
build_keyword("MIcrosoft Corp")
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
build_keyword("MIcrosoft Corp")
build_keyword("EMPIRE NV")
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
from gdeltdoc import GdeltDoc, Filters
import pandas as pd
import time
gd = GdeltDoc()
results = []
ESG_THEMES = [  # http://data.gdeltproject.org/api/v2/guides/LOOKUP-GKGTHEMES.TXT
"WB_1786_ENVIRONMENTAL_SUSTAINABILITY",
"WB_2089_ETHICS_AND_CODES_OF_CONDUCT",
"WB_417_CORPORATE_GOVERNANCE",
"WB_2507_HUMAN_RIGHTS_ABUSES_AND_VIOLATIONS"
]
TRUSTED_DOMAINS = [
"reuters.com",
"bloomberg.com",
"ft.com",
"wsj.com",
"nytimes.com",
"theguardian.com",
"economist.com"
]
for _, row in data_holdings.iterrows():
keyword = build_keyword(row["Name"])
for theme in ESG_THEMES:
try:
f = Filters(
keyword=keyword,
language="English",
theme=theme,
#domain=TRUSTED_DOMAINS,
start_date="2023-01-01",
end_date="2025-12-26"
)
articles = gd.article_search(f)
if articles is None or len(articles) == 0:
continue
gkg = pd.DataFrame(articles)
# Add metadata
gkg["ISIN"] = row["ISIN"]
gkg["Name"] = row["Name"]
gkg["Theme"] = theme
results.append(gkg)
time.sleep(0.5)  # avoid throttling
except Exception as e:
print(f"Error for {row['Name']} | Theme {theme}: {e}")
# Combine all results
news_df_original = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
from gdeltdoc import GdeltDoc, Filters
import pandas as pd
import time
gd = GdeltDoc()
results = []
ESG_THEMES = [  # http://data.gdeltproject.org/api/v2/guides/LOOKUP-GKGTHEMES.TXT
"WB_1786_ENVIRONMENTAL_SUSTAINABILITY",
"WB_2089_ETHICS_AND_CODES_OF_CONDUCT",
"WB_417_CORPORATE_GOVERNANCE",
"WB_2507_HUMAN_RIGHTS_ABUSES_AND_VIOLATIONS"
]
TRUSTED_DOMAINS = [
"reuters.com",
"bloomberg.com",
"ft.com",
"wsj.com",
"nytimes.com",
"theguardian.com",
"economist.com"
]
for _, row in data_holdings.iterrows():
keyword = build_keyword(row["Name"])
for theme in ESG_THEMES:
try:
f = Filters(
keyword=keyword,
language="English",
theme=theme,
#domain=TRUSTED_DOMAINS,
start_date="2023-01-01",
end_date="2025-12-26"
)
articles = gd.article_search(f)
if articles is None or len(articles) == 0:
continue
gkg = pd.DataFrame(articles)
# Add metadata
gkg["ISIN"] = row["ISIN"]
gkg["Name"] = row["Name"]
gkg["Theme"] = theme
results.append(gkg)
time.sleep(0.5)  # avoid throttling
except Exception as e:
print(f"Error for {row['Name']} | Theme {theme}: {e}")
# Combine all results
news_df_original = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
View(news_df_original)
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
from gdeltdoc import GdeltDoc, Filters
import pandas as pd
import time
gd = GdeltDoc()
results = []
ESG_THEMES = [  # http://data.gdeltproject.org/api/v2/guides/LOOKUP-GKGTHEMES.TXT
"WB_1786_ENVIRONMENTAL_SUSTAINABILITY",
"WB_2089_ETHICS_AND_CODES_OF_CONDUCT",
"WB_417_CORPORATE_GOVERNANCE",
"WB_2507_HUMAN_RIGHTS_ABUSES_AND_VIOLATIONS"
]
TRUSTED_DOMAINS = [
"reuters.com",
"bloomberg.com",
"ft.com",
"wsj.com",
"nytimes.com",
"theguardian.com",
"economist.com"
]
for _, row in data_holdings.iterrows():
keyword = build_keyword(row["Name"])
for theme in ESG_THEMES:
try:
f = Filters(
keyword=keyword,
language="English",
theme=theme,
#domain=TRUSTED_DOMAINS,
start_date="2023-01-01",
end_date="2025-12-26"
)
articles = gd.article_search(f)
if articles is None or len(articles) == 0:
continue
gkg = pd.DataFrame(articles)
# Add metadata
gkg["ISIN"] = row["ISIN"]
gkg["Name"] = row["Name"]
gkg["Theme"] = theme
results.append(gkg)
time.sleep(0.5)  # avoid throttling
except Exception as e:
print(f"Error for {row['Name']} | Theme {theme}: {e}")
# Combine all results
news_df_original = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Determines if a word is a common English word (likely a common noun)
rather than a proper noun.
Zipf frequency scale (approximate):
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
Heuristic:
- Only expand if lowercase usage is frequent
- And lowercase usage is more frequent than uppercase usage
"""
freq_lower = zipf_frequency(word.lower(), 'en')
freq_upper = zipf_frequency(word.upper(), 'en')
# Only treat as common word if lowercase is frequent and more common than uppercase
return freq_lower >= threshold and freq_lower > freq_upper
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
build_keyword("EMPIRE NV")
"empre".upper()
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Determines if a word is a common English word (likely a common noun)
rather than a proper noun, using lowercase frequency and initial capitalization.
Heuristic:
- Only expand if lowercase frequency is above threshold
- And the word is not mostly used with an initial capital (proper noun)
"""
# Frequency of lowercase usage
freq_lower = zipf_frequency(word.lower(), 'en')
# Frequency of the word with initial capital (titlecase)
freq_title = zipf_frequency(word.title(), 'en')
# Treat as common word if lowercase is frequent and more frequent than titlecase
return freq_lower >= threshold and freq_lower > freq_title
build_keyword("EMPIRE NV")
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
freq_lower = zipf_frequency("EMPIRE".lower(), 'en')
freq_lower
freq_title = zipf_frequency("EMPIRE".title(), 'en')
freq_title
"EMPIRE".title()
build_keyword("MICROSOFT")
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
build_keyword("MICROSOFT")
data_holdings[1]
data_holdings["Name"]
is_common_english_word(data_holdings["Name"])
data_holdings["is_common_word"] = data_holdings["Name"].apply(is_common_english_word)
View(data_holdings)
import re
def clean_company_name(name):
# Uppercase for consistency
name = name.upper()
# Remove common legal suffixes
suffixes = [
r'\bINC\b', r'\bCORP\b', r'\bCORPORATION\b',
r'\bGROUP\b', r'\bGROEP\b',
r'\bNV\b', r'\bAG\b',
r'\bLTD\b', r'\bLIMITED\b', r'\bCO\b',
r'\bCLASS A\b', r'\bCLASS B\b', r'\bPLC\b'
]
for s in suffixes:
name = re.sub(s, '', name)
# Replace & with space
name = name.replace('&', ' ')
# Remove extra whitespace
name = re.sub(r'\s+', ' ', name).strip()
return name
from wordfreq import zipf_frequency
def is_common_english_word(word, threshold=3.5):
"""
Zipf frequency:
~1–2  rare
~3    uncommon
~4–5  common
~6–7  very common
"""
return zipf_frequency(word.lower(), 'en') >= threshold
# Proper nouns are sometimes also included with high frequency. Ideally, this is not the case.
def build_keyword(name):
cleaned = clean_company_name(name)
# If very short or common English word, expand the query with "company"
if (len(cleaned) <= 4) or (is_common_english_word(cleaned)):
return f'"{cleaned}" AND "company"'
# Quote multi-word company names
if ' ' in cleaned:
return f'"{cleaned}"'
return cleaned
# install extra packages
reticulate::py_install("nltk.corpus", envname = "esg-py")
# install extra packages
reticulate::py_install("nltk", envname = "esg-py")
library(reticulate)
reticulate::use_virtualenv("esg-py", required = TRUE)
reticulate::repl_python()
